{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from cikm_dataloader import get_dataset\n",
    "from densenet import generate_model\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "device = torch.device('cuda:3')\n",
    "import glob\n",
    "from collections import OrderedDict\n",
    "from efficientnet_pytorch_3d import EfficientNet3D\n",
    "from sklearn.metrics import precision_score, f1_score, accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_efficientnet_model(model_path, device):\n",
    "    model = EfficientNet3D.from_name('efficientnet-b6', override_params={'num_classes': 2})\n",
    "    state_dict = torch.load(model_path)\n",
    "    model.load_state_dict(state_dict['state_dict'])\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_densenet_model(model_path, device):\n",
    "    model = generate_model(121)\n",
    "    state_dict = torch.load(model_path)\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict['state_dict'].items():\n",
    "        new_state_dict[k.replace(\"backbone.\", \"\")] = v\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_and_get_metrics(model, test_loader, device):\n",
    "    with torch.no_grad():\n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "        for data in test_loader:\n",
    "            img, label = data[:2]\n",
    "            label = label.to(torch.float32) \n",
    "            label = label.to(device)\n",
    "            img = img.squeeze()\n",
    "            img = img.to(device)\n",
    "            outputs = model(img)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            all_labels.extend(label.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "        tp = np.sum((np.array(all_predictions) == 1) & (np.array(all_labels) == 1))\n",
    "        tn = np.sum((np.array(all_predictions) == 0) & (np.array(all_labels) == 0))\n",
    "        fp = np.sum((np.array(all_predictions) == 1) & (np.array(all_labels) == 0))\n",
    "        fn = np.sum((np.array(all_predictions) == 0) & (np.array(all_labels) == 1))\n",
    "\n",
    "        precision = precision_score(all_labels, all_predictions, zero_division=1)\n",
    "        f1 = f1_score(all_labels, all_predictions, zero_division=1)\n",
    "        accuracy = accuracy_score(all_labels, all_predictions)\n",
    "        specificity = tn / (tn + fp)\n",
    "        sensitivity = tp / (tp + fn)\n",
    "\n",
    "        return precision, f1, accuracy, specificity, sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adni_test_set= get_dataset('train', '/home/barisbaydargil/3D_classification/adni_prep_20perc_test.csv')\n",
    "oasis_test_set = get_dataset('train', '/home/barisbaydargil/3D_classification/oasis_fulltest.csv')\n",
    "\n",
    "adni_test_loader = data.DataLoader(adni_test_set, batch_size=16, shuffle=False, num_workers=6)\n",
    "oasis_test_loader = data.DataLoader(oasis_test_set, batch_size=16, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "effnet_adni_model_paths = glob.glob('/home/barisbaydargil/3D_classification/31May_classification_mixup/model_checkpoints/EfficientNet3D/adni_only/*')\n",
    "effnet_adnifake_model_paths = glob.glob('/home/barisbaydargil/3D_classification/31May_classification_mixup/model_checkpoints/EfficientNet3D/adni_fake/*')\n",
    "densenet_adni_model_paths = glob.glob('/home/barisbaydargil/3D_classification/31May_classification_mixup/model_checkpoints/DenseNet1213D/adni_only/*')\n",
    "densenet_adnifake_model_paths = glob.glob('/home/barisbaydargil/3D_classification/31May_classification_mixup/model_checkpoints/DenseNet1213D/adni_fake/*')\n",
    "\n",
    "model_paths = [\n",
    "    (\"EfficientNet\", \"adni_only\", effnet_adni_model_paths),\n",
    "    (\"EfficientNet\", \"adni_fake\", effnet_adnifake_model_paths),\n",
    "    (\"DenseNet\", \"adni_only\", densenet_adni_model_paths),\n",
    "    (\"DenseNet\", \"adni_fake\", densenet_adnifake_model_paths),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running experiments on ADNI dataset\n",
      "\n",
      "Running experiment with EfficientNet on adni_only data\n",
      "Precision: Mean=1.0000, Stddev=0.0000\n",
      "F1_score: Mean=0.9344, Stddev=0.0321\n",
      "Accuracy: Mean=0.9165, Stddev=0.0401\n",
      "Specificity: Mean=1.0000, Stddev=0.0000\n",
      "Sensitivity: Mean=0.8787, Stddev=0.0583\n",
      "\n",
      "Running experiment with EfficientNet on adni_fake data\n",
      "Precision: Mean=1.0000, Stddev=0.0000\n",
      "F1_score: Mean=0.6439, Stddev=0.2811\n",
      "Accuracy: Mean=0.6789, Stddev=0.1962\n",
      "Specificity: Mean=1.0000, Stddev=0.0000\n",
      "Sensitivity: Mean=0.5333, Stddev=0.2851\n",
      "\n",
      "Running experiment with DenseNet on adni_only data\n",
      "Precision: Mean=1.0000, Stddev=0.0000\n",
      "F1_score: Mean=0.9110, Stddev=0.0952\n",
      "Accuracy: Mean=0.8963, Stddev=0.1011\n",
      "Specificity: Mean=1.0000, Stddev=0.0000\n",
      "Sensitivity: Mean=0.8493, Stddev=0.1469\n",
      "\n",
      "Running experiment with DenseNet on adni_fake data\n",
      "Precision: Mean=0.9987, Stddev=0.0027\n",
      "F1_score: Mean=0.5773, Stddev=0.3311\n",
      "Accuracy: Mean=0.6468, Stddev=0.2422\n",
      "Specificity: Mean=0.9971, Stddev=0.0059\n",
      "Sensitivity: Mean=0.4880, Stddev=0.3539\n",
      "\n",
      "Running experiments on OASIS dataset\n",
      "\n",
      "Running experiment with EfficientNet on adni_only data\n",
      "Precision: Mean=0.8065, Stddev=0.1179\n",
      "F1_score: Mean=0.3243, Stddev=0.0215\n",
      "Accuracy: Mean=0.6246, Stddev=0.0145\n",
      "Specificity: Mean=0.9508, Stddev=0.0493\n",
      "Sensitivity: Mean=0.2069, Stddev=0.0302\n",
      "\n",
      "Running experiment with EfficientNet on adni_fake data\n",
      "Precision: Mean=0.9545, Stddev=0.0661\n",
      "F1_score: Mean=0.2424, Stddev=0.1224\n",
      "Accuracy: Mean=0.6206, Stddev=0.0301\n",
      "Specificity: Mean=0.9921, Stddev=0.0118\n",
      "Sensitivity: Mean=0.1448, Stddev=0.0735\n",
      "\n",
      "Running experiment with DenseNet on adni_only data\n",
      "Precision: Mean=0.8348, Stddev=0.1100\n",
      "F1_score: Mean=0.3256, Stddev=0.0144\n",
      "Accuracy: Mean=0.6302, Stddev=0.0089\n",
      "Specificity: Mean=0.9630, Stddev=0.0290\n",
      "Sensitivity: Mean=0.2041, Stddev=0.0179\n",
      "\n",
      "Running experiment with DenseNet on adni_fake data\n",
      "Precision: Mean=0.8968, Stddev=0.1893\n",
      "F1_score: Mean=0.2030, Stddev=0.1594\n",
      "Accuracy: Mean=0.5966, Stddev=0.0377\n",
      "Specificity: Mean=0.9583, Stddev=0.0806\n",
      "Sensitivity: Mean=0.1333, Stddev=0.1104\n"
     ]
    }
   ],
   "source": [
    "# Create list of datasets to iterate over\n",
    "datasets = [\n",
    "    ('ADNI', adni_test_loader),\n",
    "    ('OASIS', oasis_test_loader),\n",
    "]\n",
    "\n",
    "# Loop over each dataset\n",
    "for dataset_name, test_loader in datasets:\n",
    "    print(f'\\nRunning experiments on {dataset_name} dataset')\n",
    "    \n",
    "    # Perform inference for each model on current dataset\n",
    "    for model_name, experiment, paths in model_paths:\n",
    "        all_metrics = {\n",
    "            'precision': [],\n",
    "            'f1_score': [],\n",
    "            'accuracy': [],\n",
    "            'specificity': [],\n",
    "            'sensitivity': []\n",
    "        }\n",
    "\n",
    "        print(f\"\\nRunning experiment with {model_name} on {experiment} data\")\n",
    "\n",
    "        for model_path in paths:\n",
    "            if model_name == \"EfficientNet\":\n",
    "                model = load_efficientnet_model(model_path, device)\n",
    "            elif model_name == \"DenseNet\":\n",
    "                model = load_densenet_model(model_path, device)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            precision, f1, accuracy, specificity, sensitivity = run_inference_and_get_metrics(model, test_loader, device)\n",
    "            \n",
    "            all_metrics['precision'].append(precision)\n",
    "            all_metrics['f1_score'].append(f1)\n",
    "            all_metrics['accuracy'].append(accuracy)\n",
    "            all_metrics['specificity'].append(specificity)\n",
    "            all_metrics['sensitivity'].append(sensitivity)\n",
    "\n",
    "        mean_metrics = {}\n",
    "        std_metrics = {}\n",
    "        for metric_name, metric_values in all_metrics.items():\n",
    "            mean_value = np.mean(metric_values)\n",
    "            std_value = np.std(metric_values)\n",
    "            mean_metrics[metric_name] = mean_value\n",
    "            std_metrics[metric_name] = std_value\n",
    "\n",
    "        for metric_name, mean_value in mean_metrics.items():\n",
    "            std_value = std_metrics[metric_name]\n",
    "            print(f'{metric_name.capitalize()}: Mean={mean_value:.4f}, Stddev={std_value:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
